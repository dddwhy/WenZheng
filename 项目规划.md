# 省级政府机构数据抓取与存储项目开发指南

**项目目标:**

*   构建一个自动化系统，定期从指定API抓取中国省级和市州-区县政府机构的组织结构数据。
*   将抓取的数据以结构化方式存储到 PostgreSQL 数据库中，利用 `ltree` 扩展优化树形结构存储和查询。
*   提供方便的数据查询工具，支持各种查询需求和数据分析功能。

**技术栈选型:**

*   **编程语言:** Python 3.8+ (通用性强，易于数据处理，拥有丰富的库)
*   **数据库:** PostgreSQL (关系型数据库，数据可靠性高，支持高级数据类型 `ltree`，擅长处理树形结构)
*   **异步HTTP请求:** `aiohttp` (Python异步HTTP客户端/服务器，提高爬虫效率)
*   **数据库连接库:** `psycopg2` (Python库，用于连接PostgreSQL数据库)
*   **配置管理:** YAML格式配置文件 (灵活配置数据库连接、API参数等)

**项目架构:**

1. **配置模块**: 使用YAML格式管理所有配置，便于动态调整参数
2. **日志模块**: 统一的日志记录机制，提供不同级别的日志输出
3. **爬虫模块**: 基于爬虫基类实现多种爬虫，支持不同类型数据的抓取
4. **数据库模块**: 统一的数据库连接管理，封装底层数据库操作
5. **数据处理模块**: 将抓取的数据转换为适合存储的格式并保存到数据库
6. **数据查询模块**: 提供各种查询接口，满足不同的数据访问需求

**项目已实现的核心组件:**

1. **数据库连接管理器 (`DBManager`)**
   - 提供统一的数据库连接管理
   - 支持SQL执行、查询结果获取等核心功能
   - 实现异常处理和日志记录
   - 支持上下文管理器模式（with语句）

2. **数据库初始化模块 (`DatabaseInitializer`)**
   - 创建必要的PostgreSQL扩展（如ltree）
   - 初始化数据库表结构
   - 创建必要的索引，优化查询性能

3. **爬虫基类与实现 (`BaseCrawler`, `OrganizationCrawler`)**
   - 封装HTTP请求逻辑
   - 提供统一的错误处理和重试机制
   - 支持自定义存储目录
   - 基于基类实现特定的爬虫类

4. **数据处理模块 (`OrganizationDataProcessor`)**
   - 处理JSON格式的爬取数据
   - 将数据转换为数据库存储格式
   - 处理树形结构数据的父子关系
   - 优化数据更新逻辑

5. **数据查询服务 (`OrganizationQuery`)**
   - 提供多种查询方法（ID查询、层级查询、搜索等）
   - 支持树形结构数据的查询
   - 提供数据统计功能

6. **命令行工具**
   - 数据导入工具：将爬取的JSON数据导入数据库
   - 数据查询工具：通过命令行快速查询组织机构数据
   - 爬虫执行工具：控制爬虫的运行

**数据库设计:**

1. **organizations表**: 存储组织机构数据
   - 使用ltree类型存储路径信息，优化树形结构查询
   - 创建必要的索引，提高查询性能
   - 支持JSON扩展字段，灵活存储额外信息

2. **crawl_tasks表**: 记录爬虫任务执行情况
   - 记录任务开始时间、完成时间、状态等信息
   - 存储任务参数和结果摘要
   - 方便任务跟踪和问题排查

**数据流转流程:**

1. **爬虫模块** 从API抓取组织机构数据，保存为JSON文件
2. **数据处理模块** 读取JSON文件，解析数据结构
3. **数据库模块** 将解析后的数据存储到PostgreSQL数据库
4. **数据查询模块** 提供各种查询接口，满足业务需求

**开发标准:**

*   **代码规范:** 
    *   遵循PEP 8代码风格指南，保持代码可读性和一致性
    *   使用有意义的变量名和函数名
    *   编写必要的注释，解释代码逻辑和关键步骤
    *   模块化设计，将不同功能封装成独立的函数和类

*   **错误处理:** 
    *   使用异常处理机制，捕获并处理各种可能的异常
    *   记录详细的错误信息，方便问题排查
    *   设计合理的错误恢复机制，提高系统稳定性

*   **日志记录:** 
    *   统一的日志记录机制，支持不同级别的日志输出
    *   记录关键操作的执行情况和结果
    *   记录错误和异常信息，方便排查问题

**后续扩展方向:**

1. **Web接口开发**:
   - 开发REST API，提供数据访问服务
   - 构建Web前端展示界面，可视化组织机构数据

2. **任务调度系统**:
   - 实现自动化的爬虫任务调度
   - 支持定时任务、条件触发等功能
   - 提供任务监控和告警机制

3. **数据分析功能**:
   - 实现更高级的数据分析功能
   - 提供数据可视化展示
   - 支持多维度数据统计和分析

4. **数据验证与清洗**:
   - 增强数据验证和清洗功能
   - 处理异常数据和脏数据
   - 提高数据质量和可用性

**使用指南:**

1. **环境准备**:
   - 安装PostgreSQL数据库
   - 安装Python 3.8+
   - 安装必要的Python依赖包

2. **配置文件**:
   - 修改`config/config.yaml`，设置数据库连接参数、API参数等

3. **数据库初始化**:
   - 运行`python -m src.db.create_db`创建数据库和用户
   - 运行`python -m src.db.init_db`初始化数据库表结构

4. **数据抓取与导入**:
   - 运行`python -m src.run_crawler --type organization`抓取组织机构数据
   - 运行`python -m src.scripts.import_data --dir [数据目录]`导入数据

5. **数据查询**:
   - 运行`python -m src.scripts.query_data --stats`查看数据统计信息
   - 运行`python -m src.scripts.query_data --top`查询顶级组织机构
   - 运行`python -m src.scripts.query_data --children [ID]`查询子组织机构
   - 运行`python -m src.scripts.query_data --search [关键词]`搜索组织机构
   - 运行`python -m src.scripts.query_data --node-tree [ID]`查看组织机构树

**注意事项:**

*   **API稳定性**: 第三方API可能会有变更，需要定期检查和适配
*   **数据库备份**: 定期备份数据库，防止数据丢失
*   **错误监控**: 关注日志中的错误信息，及时处理问题
*   **性能优化**: 随着数据量增加，可能需要进一步优化查询性能